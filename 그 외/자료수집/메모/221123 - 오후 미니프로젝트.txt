 - 여러분 반가워요~ 
 - 오늘까지의 중간점검 
     1. 우리가 받은 파일의 도메인에 대한 지식이 얼마나 정리되어 있는가



     2. 우리가 전처리를 했는데 혹여나 더 필요한 전처리가 있지는 않은가.
	- 우리가 처리한 전처리 기법 
		a. 결측치를 처리함. FTBN만 결측치처리를 할때 InterativeImpute를 사용  
		b. 연관성이 너무 없고 결측치가 많다라고 판단되는 feature는 삭제   
	- 해당 feature    
	- 전처리하는 방법   


     3. 스케일링에 사용한 기법 
	- StandardSacler     ★
	- PCA
        - 편향을 줄이기 위한 노력 
		a. 오버샘플링  ★,     언더샘플링   ☆     
		b. K-Fold, stratified K-Fold  ★ (알고리즘 적용파트에 기입)
		c. 로지스틱회귀를 사용할때 거의 절반의 확률을 가지고 있는 데이터를 삭제해보려고 함. 

 
     4. 많은 알고리즘을 시행해보았는데 더 시행해볼수 있는 알고리즘이 더 없는가. 
	- 훈련세트와 테스트세트로 분리 
	- 지도학습	
		a. 로지스틱  
		b. 부팅 : KNN, 결정트리, SVC
		c. 배깅 : RandomForest 
		d. 부스팅계열 : XGBoost, lightGBM, NGBoost, AdaBoost, CatBoost   ★
	- 비지도학습
		a. K-means  
		b. DBSCAN 

     5. 스태킹 앙상블을 이용하여 최종적인 점수를 더 높여야 할 것으로 판단되어 진다.    ★


     6. ★오늘의 과업★
	- 스태킹앙상블을 이용(동률)
	- NGBoost를 시도하고 완료(보원) 
	- PCA를 이용해서 알고리즘을 다시한번 시도(승우)
	- Voting계열 손보기(보원)
	- 개발서, PPT는 어디까지 완성?  (혜빈)
		a. 전처리와 분석파트 완료
		b. 시각화는 중간중간에 넣는걸로
		c. 편향에 대한 부분 넣기
	- 이상치 처리 (다같이) 
	- 마무리되고 난 이후에 시각화 (다같이)




 - 긴급 완전 중요한 정보 까지는 아닐수도 있지만 중요한 정보
	a. 우리는 지금까지 각 feature들을 모두 StandardScaler를 이용해서 정규화 시킴(범주형 데이터 제외)
	b. 그런데 그렇게 하기보다 feature별로 서로 다른 스케일링을 해도 좋다라고 하심. 
	   우리가 정규화를 시키려고 했던 이유는 분포를 정규분포로 만들기 위해서 였지만 정규성이 없는 데이터도 있었음.
	   그런 데이터들은 로그변환을 이용하면 좋을것 같다고 하심
	c. 그리고 feature importance 그래프를 이용하여 우리가 사용하는 부스팅계열의 알고리즘들이 각각
           동일한 feature importance의 경향을 보이면 영향이 미비한 feature들을 삭제하는 방향으로 하자. 




 - 중간점검

     1. 혜빈 :   - 훈련용 모델생성 파트 들어감. 
		- 전처리가 아직 끝나지 않아서 더 추가할 필요성이 있다. 
		- k-fold 아래 파트에 들어갈 예정
		- 테스트 모델 생성은 보류(나머지 사람들이 아직 안끝나서 못함..)
		- 개발서와 ppt의 진행상황이 동일

    2. 보원 : a. yeo-jonhson으로 스케일링
	     b. isolation forest를 FTBN을 0으로 한 상태로 했음. 
	     c. hyperOpt를 했을때 
		재현율과 macro f1 score가 더 떨어짐 (비교대상 lightGBM - yeo-jonhson)
	     d. hyperOpt X, 이상치제거 X 다시 머신러닝 돌림
		- 파라미터 : n_estimator = 200, num_leaves = 64, n_jobs = -1, boost_from_average = False
		- 결과는 이상치 드랍을 하지 않았을때가 더 좋게 나옴. 
		- 혼동행렬 (2종오류 93개, 1종오류 11개, auc = 0.9170, macro = 0.86, 정확도 = 0.96, 
		 	정밀도 = 0.93, 재현율 = 0.61, f1 = 0.74
		 	
		
    3. 승우 :  a. min-max로 스케일링을 진행. 폭망
	      b. logscale : 과소적합 현상이 나타남
		- gridsearch & XGBoost를 이용했을때 점수가 제일 잘 나왔지만 오차행렬은 그대로
		- 혼동행렬 (2종오류 91개, 1종오류 12개), auc = 0.8993, macro = 0.8623, 정확도 = 0.96, 
		 	정밀도 = 0.925, 재현율 = 0.62, f1 = 0.74
	      c. 다른 모델들도 다 비슷함. 
	      d. standardScaler을 거친 데이터 파라미터 튜닝을 했을때 auc = 90 하지만 다른 점수는 떨어짐
	      e. 원본데이터가 오버샘플링 한것보다 더 좋음. 
	      f. NormalizerScaler 전반적으로 점수가 낮았음. 
	      g. 지금은 전처리를 다시 해봐야할것 같음. 		


    4. 동률 : a. 원본 : XGBoost : 오차 행렬
				[[2564   14]
				 [  91  150]]
				정확도 : 0.9628, 정밀도 : 0.9146, 재현율 : 0.6224, F1 : 0.7407, AUC : 0.9203
				Macro f1 socre :  0.860337884224756
				Micro f1 socre :  0.9627527492018446
		      
		      lightGBM : 오차 행렬
				[[2565   13]
 				[  94  147]]
				정확도 : 0.9620, 정밀도 : 0.9187, 재현율 : 0.6100, F1 : 0.7332, AUC : 0.9212
				Macro f1 socre :  0.85636776875836
				Micro f1 socre :  0.9620432777580702
	
	 	      NGBoost  : 오차 행렬
				[[2574    4]
 				[ 100  141]]
				정확도 : 0.9631, 정밀도 : 0.9724, 재현율 : 0.5851, F1 : 0.7306, AUC : 0.9031
				Macro f1 socre :  0.8553839839942543


	     b. 오버 : XGBoost : 오차 행렬
				[[2565   13]
				 [  93  148]]
				정확도 : 0.9624, 정밀도 : 0.9193, 재현율 : 0.6141, F1 : 0.7363, AUC : 0.9222
				Macro f1 socre :  0.8580369732696335
				Micro f1 socre :  0.9623980134799575


		      lightGBM : 오차 행렬
				[[2560   18]
 				[  94  147]]
				정확도 : 0.9603, 정밀도 : 0.8909, 재현율 : 0.6100, F1 : 0.7241, AUC : 0.9209
				Macro f1 socre :  0.8513656016028683
				Micro f1 socre :  0.9602695991486343

 		      NGBoost : 오차 행렬
				[[2483   95]
 				[  80  161]]
				정확도 : 0.9379, 정밀도 : 0.6289, 재현율 : 0.6680, F1 : 0.6479, AUC : 0.8977
				Macro f1 socre :  0.8069236269591875

		★ 스태킹은 각 알고리즘의 파라미터 튜닝과 더불어 마지막에 선정할 알고리즘도 정해야하기 때문에 시간이 더 필요하다. ★

	     c. 스태킹 - 원본
			오차 행렬
			[[2570    8]
			 [  98  143]]
			정확도 : 0.9624, 정밀도 : 0.9470, 재현율 : 0.5934, F1 : 0.7296, AUC : 0.8060




	     d. 스태킹 - 오버 
			오차 행렬
			[[2570    8]
 			[  98  143]]
			정확도 : 0.9624, 정밀도 : 0.9470, 재현율 : 0.5934, F1 : 0.7296, AUC : 0.8060



 - 오후에 우리가 해야할 과업

	- 전처리를 마무리 짓고 알고리즘 다시 돌리기
        - 결과를 시각화하기  
	
	- XGBoost : 
		     시각화 - 원본 : 혼동해렬, 재현률-정밀도 그래프, roc-auc, feature importance
			 - 오버 : 혼동해렬, 재현률-정밀도 그래프, roc-auc, feature importance

	- lightGBM : 
		     시각화 - 원본 : 혼동해렬, 재현률-정밀도 그래프, roc-auc, feature importance
			 - 오버 : 혼동해렬, 재현률-정밀도 그래프, roc-auc, feature importance

	- NGBoost : 
		     시각화 - 원본 : 혼동해렬, 재현률-정밀도 그래프, roc-auc, feature importance
			 - 오버 : 혼동해렬, 재현률-정밀도 그래프, roc-auc, feature importance







     